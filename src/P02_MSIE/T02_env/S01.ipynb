{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00d3b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from P02_MSIE.T01_prototype_class.DE_IM_VRPTW_classV4 import VRPTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c8cd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIMH_ENV(gym.Env):\n",
    "    def __init__(self, vrp, interval_it = 100):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Box(\n",
    "            low = np.array([0, 0, 0], dtype=np.float32), \n",
    "            high= np.array([5, 5, 1], dtype=np.float32), \n",
    "            shape=(3,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "            # order = [\n",
    "        #     \"best_solution\",\n",
    "        #     \"F\",\n",
    "        #     \"CR\",\n",
    "        #     \"MG\",\n",
    "        #     \"percent_convergence\",\n",
    "        #     \"std_pop\",\n",
    "        #     \"count_total_iteration\",\n",
    "        # ]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([-2, 0, 0, 0, 0, 0, 0], dtype=np.float32),\n",
    "            high=np.array([2, 10, 10, 1, 1, 1, 1e5], dtype=np.float32),\n",
    "            shape=(7,),  # 7 features\n",
    "            dtype=np.float64,\n",
    "        )\n",
    "        self.vrp = vrp\n",
    "        self.interval_it = interval_it\n",
    "        pass\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \n",
    "        state = self.vrp.get_current_state()\n",
    "        obs = np.array(\n",
    "            [\n",
    "                np.float64(state[\"best_solution\"]),\n",
    "                np.float64(state[\"F\"]),\n",
    "                np.float64(state[\"CR\"]),\n",
    "                np.float64(state[\"MG\"]),\n",
    "                np.float64(state[\"percent_convergence\"]),\n",
    "                np.float64(state[\"std_pop\"]),\n",
    "                np.float64(state[\"count_total_iteration\"]),\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def _get_info(self):\n",
    "        # TODO: We might want to see more stuff here.\n",
    "        \"\"\"Compute auxiliary information for debugging.\n",
    "\n",
    "        Returns:\n",
    "            dict: Info in addition to the observation\n",
    "        \"\"\"\n",
    "        return {**self.vrp.get_current_state()}\n",
    "    \n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        np.random.seed(seed or 42)\n",
    "        self.vrp.reset()\n",
    "        super().reset(seed=seed)\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.vrp.action(action)\n",
    "        self.vrp.evolve(n_iteration=self.interval_it)\n",
    "        reward = self.vrp.get_reward()\n",
    "        if self.vrp.is_terminated():\n",
    "            terminated = True\n",
    "            truncated = True\n",
    "        else:\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4514a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21086136, 3.5035124 , 0.11909813], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIMH_ENV(vrp=None).action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8ecb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = (\n",
    "    pd.read_excel(\n",
    "        r\"../../Source/rl_meta_test_data.xlsx\", sheet_name=\"distance\"\n",
    "    )\n",
    "    .fillna(9999999)\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "df_vehicle = (\n",
    "    pd.read_excel(\n",
    "        r\"../../Source/rl_meta_test_data.xlsx\", sheet_name=\"vehicle\"\n",
    "    )\n",
    "    .iloc[:, :2]\n",
    "    .to_numpy(dtype=int)\n",
    ")\n",
    "vehicle = df_vehicle[0]\n",
    "\n",
    "df_101 = pd.read_excel(\n",
    "    r\"../../Source/rl_meta_test_data.xlsx\", sheet_name=\"customer\"\n",
    ").iloc[:, 3:]\n",
    "demand = df_101.iloc[:, 0].to_numpy()\n",
    "readyTime = df_101.iloc[:, 1].to_numpy()\n",
    "dueDate = df_101.iloc[:, 2].to_numpy()\n",
    "serviceTime = df_101.iloc[:, -1].to_numpy()\n",
    "\n",
    "kwargs = {\n",
    "    \"distance\": distance,\n",
    "    \"demand\": demand,\n",
    "    \"readyTime\": readyTime,\n",
    "    \"dueDate\": dueDate,\n",
    "    \"serviceTime\": serviceTime,\n",
    "    \"vehicle\": vehicle,\n",
    "}\n",
    "\n",
    "dimensions = len(distance) - 1 + vehicle[0]\n",
    "interval_it = 10\n",
    "population_size = 4\n",
    "bounds = np.array([[0, 1]] * dimensions)\n",
    "F_rate = 0.5\n",
    "CR_rate = 0.5\n",
    "MG_rate = 0.5\n",
    "\n",
    "vrptw = VRPTW(\n",
    "    population_size=population_size,\n",
    "    dimensions=dimensions,\n",
    "    bounds=bounds,\n",
    "    distance=distance,\n",
    "    demand=demand,\n",
    "    readyTime=readyTime,\n",
    "    dueDate=dueDate,\n",
    "    serviceTime=serviceTime,\n",
    "    vehicle=vehicle,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcde38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment has issues: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\rl-meta-test\\.venv\\Lib\\site-packages\\gymnasium\\utils\\env_checker.py:333: UserWarning: \u001b[33mWARN: For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fix the environment to pass the checks\n",
    "# UserWarning: WARN: The obs returned by the `step()` method is not within the observation space.\n",
    "#   logger.warn(f\"{pre} is not within the observation space.\")\n",
    "# Environment has issues: Deterministic step observations are not equivalent for the same seed and action\n",
    "\n",
    "\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "env = AIMH_ENV(vrp=vrptw, interval_it=interval_it)\n",
    "\n",
    "# This will catch many common issues\n",
    "try:\n",
    "    check_env(env)\n",
    "    print(\"Environment passes all checks!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment has issues: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27dcf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstable_baselines3\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SAC\n\u001b[32m      3\u001b[39m model = SAC(\u001b[33m\"\u001b[39m\u001b[33mMlpPolicy\u001b[39m\u001b[33m\"\u001b[39m, env, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\rl-meta-test\\.venv\\Lib\\site-packages\\stable_baselines3\\sac\\sac.py:313\u001b[39m, in \u001b[36mSAC.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[32m    306\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    311\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    312\u001b[39m ) -> SelfSAC:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\rl-meta-test\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:321\u001b[39m, in \u001b[36mOffPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    313\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfOffPolicyAlgorithm,\n\u001b[32m    314\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    320\u001b[39m ) -> SelfOffPolicyAlgorithm:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     total_timesteps, callback = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m     callback.on_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mYou must set the environment before calling learn()\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\rl-meta-test\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:304\u001b[39m, in \u001b[36mOffPolicyAlgorithm._setup_learn\u001b[39m\u001b[34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    298\u001b[39m     \u001b[38;5;28mself\u001b[39m.action_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    299\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.num_envs > \u001b[32m1\u001b[39m\n\u001b[32m    300\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.action_noise, VectorizedActionNoise)\n\u001b[32m    301\u001b[39m ):\n\u001b[32m    302\u001b[39m     \u001b[38;5;28mself\u001b[39m.action_noise = VectorizedActionNoise(\u001b[38;5;28mself\u001b[39m.action_noise, \u001b[38;5;28mself\u001b[39m.env.num_envs)\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\rl-meta-test\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:423\u001b[39m, in \u001b[36mBaseAlgorithm._setup_learn\u001b[39m\u001b[34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    422\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28mself\u001b[39m._last_obs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28mself\u001b[39m._last_episode_starts = np.ones((\u001b[38;5;28mself\u001b[39m.env.num_envs,), dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m    425\u001b[39m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\rl-meta-test\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:78\u001b[39m, in \u001b[36mDummyVecEnv.reset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_envs):\n\u001b[32m     77\u001b[39m     maybe_options = {\u001b[33m\"\u001b[39m\u001b[33moptions\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     obs, \u001b[38;5;28mself\u001b[39m.reset_infos[env_idx] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_seeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmaybe_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_obs(env_idx, obs)\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\rl-meta-test\\.venv\\Lib\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[39m, in \u001b[36mMonitor.reset\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m into reset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mself\u001b[39m.current_reset_info[key] = value\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mAIMH_ENV.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mself\u001b[39m.vrp.reset()\n\u001b[32m     61\u001b[39m \u001b[38;5;28msuper\u001b[39m().reset(seed=seed)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m observation = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m info = \u001b[38;5;28mself\u001b[39m._get_info()\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m observation, info\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mAIMH_ENV._get_obs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_obs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvrp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_current_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     obs = np.array(\n\u001b[32m     34\u001b[39m         [\n\u001b[32m     35\u001b[39m             np.float64(state[\u001b[33m\"\u001b[39m\u001b[33mbest_solution\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m         dtype=np.float32,\n\u001b[32m     44\u001b[39m     )\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\rl-meta-test\\src\\P02_MSIE\\T01_prototype_class\\DE_IM_VRPTW_classV4.py:360\u001b[39m, in \u001b[36mget_current_state\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;66;03m# Ensure we have enough history to compute the convergence rate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.count_total_iteration - lookback_it) < \u001b[32m0\u001b[39m:\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m.percent_convergence = \u001b[32m0\u001b[39m\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-meta-test (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
