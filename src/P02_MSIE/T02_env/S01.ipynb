{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "00d3b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from P02_MSIE.T01_prototype_class.DE_IM_VRPTW_classV4 import VRPTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3c8cd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIMH_ENV(gym.Env):\n",
    "    def __init__(self, vrp, interval_it = 100):\n",
    "        super().__init__()\n",
    "        self.action_space = spaces.Box(\n",
    "            low = np.array([0, 0, 0], dtype=np.float32), \n",
    "            high= np.array([5, 5, 1], dtype=np.float32), \n",
    "            shape=(3,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "            # order = [\n",
    "        #     \"best_solution\",\n",
    "        #     \"F\",\n",
    "        #     \"CR\",\n",
    "        #     \"MG\",\n",
    "        #     \"percent_convergence\",\n",
    "        #     \"std_pop\",\n",
    "        #     \"count_total_iteration\",\n",
    "        # ]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=np.array([-2, 0, 0, 0, 0, 0, 0], dtype=np.float32),\n",
    "            high=np.array([2, 10, 10, 1, 1, 1, 1e5], dtype=np.float32),\n",
    "            shape=(7,),  # 7 features\n",
    "            dtype=np.float64,\n",
    "        )\n",
    "        self.vrp = vrp\n",
    "        self.interval_it = interval_it\n",
    "        pass\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \n",
    "        state = self.vrp.get_current_state()\n",
    "        obs = np.array(\n",
    "            [\n",
    "                np.float64(state[\"best_solution\"]),\n",
    "                np.float64(state[\"F\"]),\n",
    "                np.float64(state[\"CR\"]),\n",
    "                np.float64(state[\"MG\"]),\n",
    "                np.float64(state[\"percent_convergence\"]),\n",
    "                np.float64(state[\"std_pop\"]),\n",
    "                np.float64(state[\"count_total_iteration\"]),\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "        \n",
    "        return obs\n",
    "    \n",
    "    def _get_info(self):\n",
    "        # TODO: We might want to see more stuff here.\n",
    "        \"\"\"Compute auxiliary information for debugging.\n",
    "\n",
    "        Returns:\n",
    "            dict: Info in addition to the observation\n",
    "        \"\"\"\n",
    "        return {**self.vrp.get_current_state()}\n",
    "    \n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        np.random.seed(seed or 42)\n",
    "        self.vrp.reset()\n",
    "        super().reset(seed=seed)\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        self.vrp.action(action)\n",
    "        self.vrp.evolve(n_iteration=self.interval_it)\n",
    "        reward = self.vrp.get_reward()\n",
    "        if self.vrp.is_terminated():\n",
    "            terminated = True\n",
    "            truncated = True\n",
    "        else:\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e4514a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.3346844 , 0.47484127, 0.48524338], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AIMH_ENV(vrp=None).action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a8ecb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = (\n",
    "    pd.read_excel(\n",
    "        r\"../../Source/rl_meta_test_data.xlsx\", sheet_name=\"distance\"\n",
    "    )\n",
    "    .fillna(9999999)\n",
    "    .to_numpy()\n",
    ")\n",
    "\n",
    "df_vehicle = (\n",
    "    pd.read_excel(\n",
    "        r\"../../Source/rl_meta_test_data.xlsx\", sheet_name=\"vehicle\"\n",
    "    )\n",
    "    .iloc[:, :2]\n",
    "    .to_numpy(dtype=int)\n",
    ")\n",
    "vehicle = df_vehicle[0]\n",
    "\n",
    "df_101 = pd.read_excel(\n",
    "    r\"../../Source/rl_meta_test_data.xlsx\", sheet_name=\"customer\"\n",
    ").iloc[:, 3:]\n",
    "demand = df_101.iloc[:, 0].to_numpy()\n",
    "readyTime = df_101.iloc[:, 1].to_numpy()\n",
    "dueDate = df_101.iloc[:, 2].to_numpy()\n",
    "serviceTime = df_101.iloc[:, -1].to_numpy()\n",
    "\n",
    "kwargs = {\n",
    "    \"distance\": distance,\n",
    "    \"demand\": demand,\n",
    "    \"readyTime\": readyTime,\n",
    "    \"dueDate\": dueDate,\n",
    "    \"serviceTime\": serviceTime,\n",
    "    \"vehicle\": vehicle,\n",
    "}\n",
    "\n",
    "dimensions = len(distance) - 1 + vehicle[0]\n",
    "interval_it = 10\n",
    "population_size = 4\n",
    "bounds = np.array([[0, 1]] * dimensions)\n",
    "F_rate = 0.5\n",
    "CR_rate = 0.5\n",
    "MG_rate = 0.5\n",
    "\n",
    "vrptw = VRPTW(\n",
    "    population_size=population_size,\n",
    "    dimensions=dimensions,\n",
    "    bounds=bounds,\n",
    "    distance=distance,\n",
    "    demand=demand,\n",
    "    readyTime=readyTime,\n",
    "    dueDate=dueDate,\n",
    "    serviceTime=serviceTime,\n",
    "    vehicle=vehicle,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dcde38e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment has issues: The first element returned by `env.reset()` is not within the observation space.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\Coding\\research\\rl-meta-test\\.venv\\Lib\\site-packages\\gymnasium\\utils\\env_checker.py:333: UserWarning: \u001b[33mWARN: For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fix the environment to pass the checks\n",
    "# UserWarning: WARN: The obs returned by the `step()` method is not within the observation space.\n",
    "#   logger.warn(f\"{pre} is not within the observation space.\")\n",
    "# Environment has issues: Deterministic step observations are not equivalent for the same seed and action\n",
    "\n",
    "\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "env = AIMH_ENV(vrp=vrptw, interval_it=interval_it)\n",
    "\n",
    "# This will catch many common issues\n",
    "try:\n",
    "    check_env(env)\n",
    "    print(\"Environment passes all checks!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment has issues: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "27dcf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "0.34524956\n",
      "0.39580968\n",
      "0.23872915\n",
      "0.5979323\n",
      "0.24985784\n",
      "0.8316244\n",
      "0.5633368\n",
      "0.5135738\n",
      "0.12065026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x1ade08f3740>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-meta-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
